<!DOCTYPE html>





<html lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.4.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.4.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.4.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="原文DOISCI-HUBAbstract跨膜蛋白(TMP transmembrane Protein)在很多生理过程中起着重要作用，如细胞识别以及细胞通讯中。他们的结构很难被获取但，同时对揭示细胞完整的功能很关键。有很多计算算法因此被发明用来填补从主序列预测结构的空白。在这个课题中，我们主要聚集于α螺旋的跨膜区段和发明了一个多尺度的深度学习管道——MemBrain 3.0来提高对拓扑结构的预测。这">
<meta name="keywords" content="deep_learning,bioinformation,ResNet">
<meta property="og:type" content="article">
<meta property="og:title" content="translation-MemBrain_3.0">
<meta property="og:url" content="http://vincentcung.github.io/2020/02/20/translate-MemBrain/index.html">
<meta property="og:site_name" content="Blog4Cung">
<meta property="og:description" content="原文DOISCI-HUBAbstract跨膜蛋白(TMP transmembrane Protein)在很多生理过程中起着重要作用，如细胞识别以及细胞通讯中。他们的结构很难被获取但，同时对揭示细胞完整的功能很关键。有很多计算算法因此被发明用来填补从主序列预测结构的空白。在这个课题中，我们主要聚集于α螺旋的跨膜区段和发明了一个多尺度的深度学习管道——MemBrain 3.0来提高对拓扑结构的预测。这">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://vincentcung.github.io/2020/02/20/translate-MemBrain/Fig1.png">
<meta property="og:image" content="http://vincentcung.github.io/2020/02/20/translate-MemBrain/Fig2.png">
<meta property="og:image" content="http://vincentcung.github.io/2020/02/20/translate-MemBrain/Fig3.png">
<meta property="og:image" content="http://vincentcung.github.io/2020/02/20/translate-MemBrain/Table1-1.png">
<meta property="og:image" content="http://vincentcung.github.io/2020/02/20/translate-MemBrain/Table1-2.png">
<meta property="og:image" content="http://vincentcung.github.io/2020/02/20/translate-MemBrain/Fig4.png">
<meta property="og:image" content="http://vincentcung.github.io/2020/02/20/translate-MemBrain/Table2.png">
<meta property="og:image" content="http://vincentcung.github.io/2020/02/20/translate-MemBrain/Table3.png">
<meta property="og:image" content="http://vincentcung.github.io/2020/02/20/translate-MemBrain/Table4.png">
<meta property="og:image" content="http://vincentcung.github.io/2020/02/20/translate-MemBrain/Table5.png">
<meta property="og:image" content="http://vincentcung.github.io/2020/02/20/translate-MemBrain/Table6.png">
<meta property="og:image" content="http://vincentcung.github.io/2020/02/20/translate-MemBrain/Fig5.png">
<meta property="og:image" content="http://vincentcung.github.io/2020/02/20/translate-MemBrain/Fig6.png">
<meta property="og:image" content="http://vincentcung.github.io/2020/02/20/translate-MemBrain/Fig7.png">
<meta property="og:image" content="http://vincentcung.github.io/2020/02/20/translate-MemBrain/Table7.png">
<meta property="og:image" content="http://vincentcung.github.io/2020/02/20/translate-MemBrain/Fig8-1.png">
<meta property="og:image" content="http://vincentcung.github.io/2020/02/20/translate-MemBrain/Fig8-2.png">
<meta property="og:image" content="http://vincentcung.github.io/2020/02/20/translate-MemBrain/Table8.png">
<meta property="og:updated_time" content="2020-02-22T11:40:56.400Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="translation-MemBrain_3.0">
<meta name="twitter:description" content="原文DOISCI-HUBAbstract跨膜蛋白(TMP transmembrane Protein)在很多生理过程中起着重要作用，如细胞识别以及细胞通讯中。他们的结构很难被获取但，同时对揭示细胞完整的功能很关键。有很多计算算法因此被发明用来填补从主序列预测结构的空白。在这个课题中，我们主要聚集于α螺旋的跨膜区段和发明了一个多尺度的深度学习管道——MemBrain 3.0来提高对拓扑结构的预测。这">
<meta name="twitter:image" content="http://vincentcung.github.io/2020/02/20/translate-MemBrain/Fig1.png">
  <link rel="canonical" href="http://vincentcung.github.io/2020/02/20/translate-MemBrain/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>translation-MemBrain_3.0 | Blog4Cung</title>
  








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Blog4Cung</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-tags">
      
    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
      <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block post">
    <link itemprop="mainEntityOfPage" href="http://vincentcung.github.io/2020/02/20/translate-MemBrain/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="GimCung Ho">
      <meta itemprop="description" content="stay hungry stay foolish">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog4Cung">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">translation-MemBrain_3.0

          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              
                
              

              <time title="创建时间：2020-02-19 23:55:33" itemprop="dateCreated datePublished" datetime="2020-02-19T23:55:33Z">2020-02-19</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-22 11:40:56" itemprop="dateModified" datetime="2020-02-22T11:40:56Z">2020-02-22</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/bioinformation/" itemprop="url" rel="index"><span itemprop="name">bioinformation</span></a></span>

                
                
              
            </span>
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>原文<a href="https://doi.org/10.1016/j.jmb.2019.12.007" target="_blank" rel="noopener">DOI</a><br><a href="https://sci-hub.si/https://doi.org/10.1016/j.jmb.2019.12.007" target="_blank" rel="noopener">SCI-HUB</a></p><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>跨膜蛋白(<code>TMP transmembrane Protein</code>)在很多生理过程中起着重要作用，如细胞识别以及细胞通讯中。他们的结构很难被获取但，同时对揭示细胞完整的功能很关键。有很多计算算法因此被发明用来填补从主序列预测结构的空白。在这个课题中，我们主要聚集于α螺旋的跨膜区段和发明了一个多尺度的深度学习管道——MemBrain 3.0来提高对拓扑结构的预测。这个新方法包含有两个子模块。第一个模块是对跨膜螺旋(<code>TMH</code>)的预测，它具有通过结合对尾部建模来精准预测具有尾部结构跨膜蛋白的特点。预测核心策略包含有深度学习模型和一个动态阈值策略。深度模型由一个小尺度残基水平(<code>residue-based</code>)残差网络和一个大尺度完整序列水平(<code>entire-sequence-based</code>)残差网络所组成。动态阈值策略是为了二值化预测分数和解决欠分割(<code>under-split</code>)的问题而设计的。第二个模块是由支持向量机和极大极小分配策略(<code>MMA Max-Min Assignment</code>)组成的方向预测器。MemBrain 3.0的主要贡献是它的设计模式由动态阈值策略和MMA策略所组成，这两者让预测器对复杂跨膜蛋白(<code>hard-TMH</code>)如半跨膜螺旋(<code>half-TMH</code>)，连续跨膜螺旋(<code>back-to-bcak TMH</code>)和长跨膜螺旋(<code>long-TMH</code>)。系统的实验已经试验了这个新模型的有效性，且模型可以在<a href="www.csbio.sjtu.edu.cn/bioinf/MemBrain/">www.csbio.sjtu.edu.cn/bioinf/MemBrain/</a>使用。</p><a id="more"></a>

<h1 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h1><p>Membrane protein; Bioinformatics; Structure prediction; Topology; Deep learning;<br>膜蛋白；生物信息；结构预测；拓扑结构；深度学习</p>
<h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><p>膜是将细胞内部和外界环境隔开来的一道屏障。它由磷脂双分子层和大量的内嵌膜蛋白所组成。先前的课题已经展示了在整个蛋白质组(<code>proteome</code>)中有30%的蛋白质是膜蛋白。他们在一系列的生理过程中起着重要作用，如细胞信号传导、离子电导交换(<code>ion conductivity</code>)、细胞凝聚(<code>cell cohesion</code>)、细胞识别、细胞间通讯。因此很多药物被设计来通过定位膜蛋白来影响生理过程。绝大多数的膜蛋白都是α螺旋跨膜蛋白。他们常见于真核生物的细胞膜上、细菌细胞的内膜，甚至是在细菌的外膜。然而通过实验判别他们的应该依然具有挑战性，因为它(指蛋白)很难被溶解、提纯、结晶化，而且他们对于核磁共振光谱法(<code>NMR nuclear magnetic resonance spectroscopy</code>)而言结构过于庞大了。在测序技术快速发展下，已知序列和已发现结构的数量有所提升。根据对已知3D结构数据库中膜蛋白的统计，跨膜蛋白的已知结构对于PDB(<code>protein Data Bank</code>)中的所有结构只占 1.8% 以下。因此，迫切需要有能从序列中准确预测出跨膜蛋白结构的自动计算技术。</p>
<p>三维结构预测通常有数个关键步骤实现。跨膜蛋白拓扑预测正是这预测过程中的一个步骤，它起着重要的作用。如在FILM3中，预测出的TMP拓扑结构被用来生成初始的构造。RosettaMembrane中也在能量函数设计也把预测出的TMP拓扑结构纳入考虑。这样优化会导致一致的低能量构象。</p>
<blockquote>
<p>In this way,optimization leads to a consensus low-energy conformation.</p>
</blockquote>
<p>最近的课题都目睹了残基接触点协助的(<code>residue contact-assisted</code>)结构预测快速发展，TMP拓扑结构依然对这类预测提供着重要信息。举个例子，有文章报告了通过提供TMH簇的重要约束能够提高预测残基接触点结构的效果。TMP拓扑也显示出与残基接触点相关的优点。存在论文显示了预测残基接触点的准确性很大程度上取决于同源序列的数量，而对于TMP拓扑预测，只需要较少的同源序列。如HMM-TOP中最多只要50条同源序列就可以达到满意的表现。这个特性让拓扑预测能够为没有足够同源蛋白序列的膜蛋白推理出可靠的残基接触点这个困难的任务提供重要线索。</p>
<p>TMP拓扑预测可以分为两个子任务：(1)TMH区段预测(2)跨膜方向的判断。过去的30年内，发展出了数十个TMH预测方法，他们能够分为三类：基于疏水性规模的方法(<code>hydrophobicity scale-based</code>)、基于机器学习的方法和基于集成的方法。</p>
<p>第一类中，疏水性规模是重要的特征，因为埋在膜内和暴露在溶液中的残基具有不同的疏水性，滑窗可以用于捕捉邻近氨基酸的疏水性，对滑窗中的疏水性规模作平均可看作中间残基的疏水性规模，一个固定的阈值被用来区分中间的残基是否属于TMH区段。</p>
<p>最近，基于机器学习的方法被广泛应用，对于数据驱动的统计模型被应用，如隐马可洛夫(HMM)、支持向量机、随机森林、k近邻。同时除了疏水性规模，试验中的一些进化信息也十分有用。TMSEG就是这个分类中的一个模型。TMSEG中的随机森林用了一个19个连续残基的滑窗的数据作为输入。包含有许多进化信息的位置特异分数矩阵(PSSM)也被应用。我们最初的版本的Membrain模型也属于这个分类。该模型利用从多序列比对获得的特征，应用被理论证明过的KNN算法进行分类。尽管这些模型在这一类有着优秀的效果，他们的表现很大程度依赖于提取的特征、应用的机器学习算法、相关的参数。</p>
<p>一致性方法(<code>consensus method</code>)构成了第三类模型，实际上它是基于集成学习的模型。如TOPCONS中，对确定的蛋白质序列，先用OCTOPUS、SCAMPI-single、PRODIV-TMHMM和PRO-TMHMM生成最初的拓扑轮廓(<code>topology profile</code>)，然后通过动态规划算法和Viterbi算法从中得出一致性的预测。这些结果展示了对拥有高度相似度的蛋白质使用这些预测方法，使用集成框架能有效提高效果。</p>
<p>拓扑预测的第二个子任务是方向的判定，对于每一个预测的TMH判断出其向内还是向外的朝向。最初，著名的正内原则(<code>postive-inside rule</code>)被应用且对后续的工作具有很长远的影响。这个原则指出细胞内侧的loop具有更多带正电的残基如<code>Lys，arg</code>。这之后，随着越来越多的可用数据，机器学习的算法被应用，如随机森林和支持向量机。TMSEG中随机森林取TMH开端(末端)8个残基和TMH前(或后)的15个残基作为输入。正电残基所占的百分比也作为特征之一被使用。在MEMSAT—SVM中，SVM使用35个残基大小的滑窗进行预测，判断中间的残基属于内侧还是外侧的loop。</p>
<p>尽管在这个领域已有很多预测器，但还有空间提高，这个课题的动机有以下三点：尾端建模、最近深度学习取得的进步，困难的TMH段：<br>(1)大部分现存的预测器都是用完全嵌入膜中的TMH来训练。这意味着粘连在膜外的尾端被视为负样本。有报告指出这些尾端对生理过程有重要作用。如化学受体CCR5上的TMH1，2，3和7的尾端形成的洞被作为了HIV-1实体进入$\mathrm{CD4}^+$细胞的位点。一些抑制剂被设计用来阻止这个过程，他们通过阻塞这个交互位点而实现阻止。整合素$\mathrm{\alpha IIb\beta3}$复合体(integrin $\mathrm{\alpha IIb\beta3}$ complex)中，从内向外的跨膜信号传导由TMH尾端-talin F3复合体实现。人类bestrophin-1一个细菌同族体的结构中，一段具有长尾端的TMH链接了一个分散的胞质区域和TMH簇，他们共同组成了离子通道。ExbB 中的TMH2，6，7在细胞质中形成了一个巨大的闭合洞(<code>large enclosed cavity</code>)并能量传导具有重要作用。在SNARE中膜泡运输依赖于由syntaxin 1A尾端形成的SNARE复合体和沿着SNARE motif上的synaptiobrevin2。考虑到他们的重要作用，我们扩展建模的范围以覆盖尾端。</p>
<blockquote>
<p>In the integrin αIIbβ3 complex, inside-out transmembrane signaling is achieved by the TMH tail-talin F3 complex [31]. In the structure of a bacterial homolog of human bestrophin-1, a TMH with a long tail connects a separate cytoplasmic domain and the TMH bundle, which together act as an ion channel [32]. The tail parts of TMH 2, 6, and 7 in ExbB form a large enclosed cavity in the cytoplasm and play an important role in energy transduction [33]. Vesicular transport relies on the SNARE complex formed by tails of syntaxin 1A and synaptobrevin 2, along with SNARE motifs in SNAP-25 [34]. Considering their important roles, we extend the modeling scope to cover the tails.</p>
</blockquote>
<p>(2)深度学习已被证明对于处理复杂的生物数据是有效的。这个课题中我们提出了多尺度的深度学习融合管道，其中小尺度网络聚焦于单独残基水平上的模型，大尺度网络聚焦于完整序列水平上的模型。我们接下来的实验结果会验证新方法的有效性。</p>
<p>(3)TMP结构是十分复杂的，并且有很多不同特殊的情况。正如下图Figure1中所示，在TMH长度上，在已经发现的结构中能够经常观察到特别长或特别短的TMH；在loop长度上，两个TMH通过一个非常短的loop所连接也是一个常见的拓扑结构。所有这些非常规的结构使一个通用的规则变得行不通。受此问题启发，在MemBrain3.0中我们设计了一个动态阈值策略来预测TMH和用极大极小得分分配策略(<code>Max-Min score assignment</code>)策略来做方向判断，MMA对于提高效果十分有效，尤其对于上述讨论中有挑战的情况。</p>
<img src="/2020/02/20/translate-MemBrain/Fig1.png" title="Fig1">
<!-- ![](translate-MemBrain/Fig1.png) -->
<blockquote>
<p>Figure 1 α螺旋TMH拓扑的示意图。由蓝色的尾端部分和橙色的内嵌部分组成的圆桶代表TMH。左侧第二个TMH是一个long-TMH，它有超过30个的残基以及一个粘连在膜外侧的长尾端。第三个TMH是一个half-TMH，它只跨越半层膜，它前后的非TMH部分的内外侧位点是一致的(the inside/outside positions of the non-TMHs before and afrer it are the same)。第4第5个TMH是一个连续的TMH(<code>back-to-back TMH</code>)，他们由不超过3个残基组成的loop所链接。</p>
</blockquote>
<h1 id="2-Material-and-Methods"><a href="#2-Material-and-Methods" class="headerlink" title="2. Material and Methods"></a>2. Material and Methods</h1><p>如前面所述，这个工作中，TMH包含两个部分：内嵌部分和尾端部分。在接下来的小节中，内嵌部分的残基称为内嵌残基，尾端部分上的残基称为尾端残基。蛋白质序列上的其他部分即TMH以外的称为非TMH(<code>non-TMH</code>)。</p>
<h2 id="2-1-Dataset"><a href="#2-1-Dataset" class="headerlink" title="2.1 Dataset"></a>2.1 Dataset</h2><p><strong>Training，validation，and test sets</strong><br>OPM(<code>Orientations of Protins in Membrane</code>)数据库是一个最新的实验性TMP结构数据库，它是这个工作数据主要来源。结构的标注、氨基酸序列信息、PDB码以及链ID都取自它。更具体而言，我们先从OPM收集两类蛋白，即α螺旋多跨膜蛋白(<code>polytopic-proteins</code>)以及双跨膜蛋白(<code>bitopic-proteins</code>)。它总共给了我们1783个PDB问卷(7814个蛋白链)。然后蛋白链根据以下情况进行进一步筛除：(i)不连续的链如，两个相邻残基的内外侧位点(<code>inside/outside positions</code>)不一致；(ii)长度少于20个残基的蛋白质链；(iii)链中没有TMH。<strong>最后有5781个蛋白质链剩下。我们选取用于TMSEG中的40个测试蛋白作为我们的独立测试集</strong>，他们共包含149个TMH，他们都是通过NMR或低于4.5埃的X射线技术得出的结果(<code>X-ray technique with resolutions less than 4.5</code>$\overset{\circ}{A}$)</p>
<p>为了进行公平的对比，我们从两个方面减少了序列冗余度：(i)40个测试蛋白和余下的5741个蛋白间的冗余；(ii)5741个蛋白之间的冗余。我们用UniqueProt降低序列冗余度，参数设置HVAL&gt;0，TMSEG工具也是这样做的。在这个阈值下，没有一组蛋白质链的相似度大于20%，其中比对的残基数大于250个。具体而言，首先，在HVAL&gt;0下，5741个蛋白质相似于40个测试蛋白中任意一个的蛋白质被移除，然后，剩下的蛋白质在HVAL&gt;0下过滤冗余度/我们最后得到380个蛋白质。为了训练的目的，我们随机选择39个蛋白质作为验证集，剩下279个蛋白组成训练集。</p>
<p>为了得到标签，我们必须知道二级结构，每个残基和膜的坐标。二级结构可以用DSSP进行计算，坐标信息可以从PDB文件中提取，标签可以根据上述的TMH定义进行生成。我们通过结合OPM的注释来处理弯折的螺旋，其中两个TMH和他们中间的弯折被融合称一段。</p>
<h2 id="2-2-protein-sequence-features"><a href="#2-2-protein-sequence-features" class="headerlink" title="2.2 protein sequence features"></a>2.2 protein sequence features</h2><p>我们在MemBrian 3.0中用了4类特征，他们在先前的工作已经被验证过有效性。</p>
<h3 id="Position-specific-scoring-matrix-PSSM"><a href="#Position-specific-scoring-matrix-PSSM" class="headerlink" title="Position-specific scoring matrix PSSM"></a>Position-specific scoring matrix PSSM</h3><p>这个特征是一种对生理序列常用的<code>motif</code>表征。它含有丰富的进化信息并且广泛在先前提到的TMH预测的方法。我们用PSI-BLAST来针对非冗余的数据库进行搜索，参数包含迭代次数3、e值为1e-6。然后PSSM会通过以下多序列比对而生成(<code>multiple sequence alignment MSA</code>)</p>
<script type="math/tex; mode=display">\begin{equation} \mathrm{PSSM}_{i,j}=\log_2 \frac{PPM_{i,j}}{b_j} \end{equation}</script><p>$i$代表序列中第$i$个位置，$j$代表20种氨基酸的第$j$种，$\mathrm{PPM}$是位置概率矩阵的缩写，$\mathrm{PPM}_{i,j}$代表在MSA中第$i$列出现第$j$种氨基酸的概率；$b_j$氨基酸$j$的背景频率，一个蛋白质序列有$L$个氨基酸，所以PSSM的维度是$L\times 20$。</p>
<h3 id="Hidden-Markov-Model-profile"><a href="#Hidden-Markov-Model-profile" class="headerlink" title="Hidden Markov Model profile"></a>Hidden Markov Model profile</h3><p>这个特征由HHblits生成，这是另一个基于HMM-HMM比对算法的同源序列搜索工具。HMM profile的维度是$L \times 30$。每一个残基都会由20维初始发射频率(<code>EF emssion frequencies</code>)、7维转变概率(<code>transition probabilities</code>)和3维局部差异性(<code>local diversities</code>)组成，EF定义如下：</p>
<script type="math/tex; mode=display">\begin{equation} \mathrm{EF}_{i,j}=-1000 \times \log_2 \mathrm{PPM}_{i,j} \end{equation}</script><p>$i,j$和$\mathrm{PPM}$与公式(1)中一样，这个研究中，我们使用Uniclust30数据库，他是我们认知中最大的HHsuite格式的数据库。迭代次数和e值分别设为3和1e-3。</p>
<h3 id="Predicted-structural-features"><a href="#Predicted-structural-features" class="headerlink" title="Predicted structural features"></a>Predicted structural features</h3><p>除了进化信息，预测得到的机构信息也被应用，包括转角、全局溶解接触描述符(<code>global solvent exposure descriptors</code>)、二级结构。所有这些特征都由SPIDER3程序预测所得。</p>
<h3 id="Hydrophobicity-scales"><a href="#Hydrophobicity-scales" class="headerlink" title="Hydrophobicity scales"></a>Hydrophobicity scales</h3><p>如Introduction节所提到的，疏水性规模在方向预测上起着关键作用，这类特征对于基于机器学习的预测器也很重要。我们在研究使用了Kyte-Doolittle尺度。</p>
<h2 id="2-3-Prediction-model"><a href="#2-3-Prediction-model" class="headerlink" title="2.3 Prediction model"></a>2.3 Prediction model</h2><h3 id="Multiscale-deep-learning-based-TMH-prediction-model"><a href="#Multiscale-deep-learning-based-TMH-prediction-model" class="headerlink" title="Multiscale deep learning-based TMH prediction model"></a>Multiscale deep learning-based TMH prediction model</h3><p>深度学习是机器学习中一个快速发展的领域。它由神经学中的交流模式所启发，并得益于大量的数据和强大的算力。在此领域已经发展了许多深度学习架构。一个出名且广泛应用的架构便是残差网络(<code>Resnet</code>)。它使用短接来解决优化中梯度小时的问题，并大幅度提高了在很多特定任务中的表现。短接的数学表达式如下：</p>
<script type="math/tex; mode=display">\begin{equation}
  y = F(x,W) + x
\end{equation}</script><p>x和y分别是输入输出，F代表了残差块，W是参数。短接会在残差块的输入输出之间执行元素的一一相加。<br><img src="/2020/02/20/translate-MemBrain/Fig2.png" title="Fig2"><br><!-- ![](translate-MemBrain/Fig2.png) --></p>
<blockquote>
<p>Figure 2 TMH预测模型的管道流。提供一个蛋白质序列，PSI-BLAST和HHblits首先分别被用于针对NR和Uniclust30寻找同源序列。同时通过SPIDER3生成结构信息，然后深度学习模型基于提取的特征作预测，最后原生的预测分数通过动态阈值策略来二值化。</p>
</blockquote>
<p>在Membrain3.0，我们使用了连个残差网络作为TMH预测模型的主要部分。他们架构相似但拥有不同的输入。一个把滑窗作为输入，另一个用完整的薛列作为输入。这样多尺度的设计有助于捕捉序列中局部和全局的关联。然后动态阈值策略被设计来二值化预测结果，解决其中欠分割的问题(两个相邻的TMH被错误预测成一个)。TMH预测管道流的如Figure2所示。</p>
<h4 id="1-The-small-scale-residue-based-Resnet"><a href="#1-The-small-scale-residue-based-Resnet" class="headerlink" title="(1) The small-scale residue-based Resnet"></a>(1) The small-scale residue-based Resnet</h4><p>残基水平残差网络的输入是一个由17个连续残基组成的滑窗。输出的是中心残基属于TMH的概率。从279个训练蛋白中，我们总共获得17437个滑窗中的中心残基在TMH中(正样本)，20003个滑窗中的中心残基在非TMH中(负样本)。交叉熵和L2正则化被作为损失函数来训练网络，定义如下：</p>
<script type="math/tex; mode=display">\begin{equation}
  Loss(y,y')=-[y'\log y+(1-y')\log (1-y) ]+\lambda\sum_{u}u^2
\end{equation}</script><p>$y$和$y’$分别是标签和预测出的概率，$\lambda$是正则化因子，$u$代表网络中所有训练的参数。</p>
<h4 id="2-The-large-scale-entire-sequence-based-Resnet"><a href="#2-The-large-scale-entire-sequence-based-Resnet" class="headerlink" title="(2) The large-scale entire-sequence-based Resnet"></a>(2) The large-scale entire-sequence-based Resnet</h4><p>整序列水平的残差网络用$L$长的完整蛋白质序列作为输入并输出长度为$L$的向量由概率分数组成。与残基水平残差网络一样，向量中的每一个分数揭示了对应参数属于TMH的概率。损失也是基于序列的，定义如下：</p>
<script type="math/tex; mode=display">\begin{equation}
  Loss(y,y')=-\frac{1}{L}\sum_{residue\ i}[y_i'\log y_i+(1-y_i')log(1-y_u)]+\lambda\sum_u u^2
\end{equation}</script><p>$y_i$和$y_i’$分别代表标签和对残基i的预测可能性。</p>
<p>程序用TensorFlow库所实现。激活函数和优化算法分别选择RELU和Adam。根据验证集的效果对超参数进行优化：两个网络$\lambda$都取5e-4，学习率都取1e-4，对于残基水平的残差网络小批量大小取40，序列水平残差网络取11。</p>
<p>被用于两个网络的蛋白质特征包括了PSSM，HMM profile和结构化特征。疏水性规模没有被采用，因为根据我们局部的实验发现他们不能有效提高效果。然而他们对方向预测有所贡献，并用在这部分的模型上。我们对两个网络的输出取平均作为原生的预测分数。一个5个残基大的滑窗平均滤波器(<code>mean filter</code>)被用来去除高频的波动。</p>
<h4 id="3-Dynamic-threshold-strategy"><a href="#3-Dynamic-threshold-strategy" class="headerlink" title="(3) Dynamic threshold strategy"></a>(3) Dynamic threshold strategy</h4><p>为了判别TMH的边界，我们必须二值化初始的预测分数。传统上，会使用固定的阈值，但是在两个TMH被一个短的loop连接时会导致欠划分的问题。为了减缓这个状况，我们应用动态阈值策略，与我们之前的课题相似。首先用0.55的初始阈值来检测出候选的TMH，然后对于每对相邻的候选TMH，如果他们之间的loop少于5个残基且loop加上TMH对的长度少于24个残基，则将两个TMH合并成一个TMH。这个合并操作可以处理过划分的问题。在这之后，每一个长于33的残基候选TMH可以看作潜在的欠划分TMH。然后，初始阈值再每轮再检测中逐步增加0.05。如果该区域有两个TMH被检测到，那么潜在的欠划分TMH便会被划分，一个额外的合并操作也会在后续被应用来纠正过划分的情况。动态阈值策略中的参数都是根据验证集的表现来判定的。</p>
<blockquote>
<p>threshold 0.55 detection -&gt; merge over-split -&gt; find potential under-split -&gt; threshold+=0.05 redetection -&gt; if 2 detected ,split potential under-split &amp; additional merge</p>
</blockquote>
<h3 id="Inside-outside-orientation-prediction"><a href="#Inside-outside-orientation-prediction" class="headerlink" title="Inside/outside orientation prediction"></a>Inside/outside orientation prediction</h3><p>相关工作中，蛋白质的氮端的位置通常是最先被预测的，然后对剩下的非TMH段进行推断，因为他们在TMH后切换。这个方法会在预测半TMH时，不可避免的导致错误的预测，半TMH的氮端、碳端残基会在同一侧如Figure1所示。已经有报告指出一个蛋白中可以找出超过1个半TMH，而且他们不一定比通常的TMH要短。这些情况都导致了方向预测的困难性。为了应对这个缺点，我们构建了一个模型来预测序列中所有非TMH的内外侧位置。这个模型由一个SVM分类起和一个stepwise极大极小得分分配的策略。管道图如下Figure3所示。<br><img src="/2020/02/20/translate-MemBrain/Fig3.png" title="Fig3"><br><!-- ![](translate-MemBrain/Fig3.png) --></p>
<blockquote>
<p>Figure3 方向预测模型的示意图。模型的输入是6个TMH残基和7个非TMH残基的结点。从一个非TMH中可以获得两个结点，即氮端结点和碳端结点。基于两类结合体训练了两个SVM分类起，两个SVM的预测取平均作为集成的预测。最后极大极小值分配算法被用来生成最后的预测。</p>
</blockquote>
<h4 id="1-SVM-based-orientation-prediction-model"><a href="#1-SVM-based-orientation-prediction-model" class="headerlink" title="(1) SVM-based orientation prediction model"></a>(1) SVM-based orientation prediction model</h4><p>结合先前课题的试验可知，TMH和非TMH之间的结点对方向判别提供了重要信息。这里我们定义结点是一个13个残基大小的窗口由6个TMH残基和7个非TMH残基组成。这个窗口的大小定义是根据验证集的效果所决定的。从279个训练蛋白中，我们取得了1259个结点，其中646在内侧，613个在外侧。</p>
<blockquote>
<p>我觉得这里还需要统计non-TMH的长度来决定非TMH窗口的大小。</p>
</blockquote>
<p>值得注意的是从非TMH中获得的两个结点。一个起始于TMH(氮端)的残基，另一个起始于非TMH(碳端)的残基。考虑到他们的差异性，基于两种结点训练了两个SVM即氮端SVM、碳端SVM。两个SVM的预测会被平均作为集成的结果。HMM profile和疏水性规模会被作为输入的特征。SVM的核函数选择rbf(<code>radial basis function</code>)，Gamma取1e-3，C取10。所有超参数都根据验证集的效果决定。SVM由sklearn库实现。</p>
<p>在试验中做预测时，我们采用集成的方法来提高效果，考虑到预测的TMH也具有不准确性。我们特意对每一个结点取5个候选不同大小的结点，对应在预测TMH取10，8，6，4，2个残基，在预测非TMH取3，5，7，9，11个残基，5个候选结点的取平均则视为原始的结点。</p>
<h4 id="2-Stepwise-Max-Min-assignment-MMA-algorithm"><a href="#2-Stepwise-Max-Min-assignment-MMA-algorithm" class="headerlink" title="(2) Stepwise Max-Min assignment(MMA) algorithm"></a>(2) Stepwise Max-Min assignment(MMA) algorithm</h4><p>为了取代使用固定的阈值，我们提出使用一个新的stepwise极大极小分配策略来做判别。首选，对所有一个蛋白内所有的非RMH，其中最高(低)的设为内侧(外侧)，然后，把剩余的非TMH们设为内侧(外侧)，如果他们更接近最高(低)的那个TMH。这个算法的假设是蛋白质中至少有一个内侧非TMH和一个外侧非TMH。因为stepwiseMMA算法只关注预测分数的相对大小，所以它更加的鲁棒且根据我们的实验显示它能比固定阈值策略更有效。</p>
<h2 id="2-4-Evaluation-measures"><a href="#2-4-Evaluation-measures" class="headerlink" title="2.4 Evaluation measures"></a>2.4 Evaluation measures</h2><p>为了评价效果，我们采用了一些测量指标，他们在先前的课题也同样被使用。</p>
<p>残基水平准确率$PRE_R$，定义如下</p>
<script type="math/tex; mode=display">\begin{equation}PRE_R=\frac{number\ of \ correctly\ predicted\ \mathbf{TMH}\ residues}{number\ of \ predicted\ \mathbf{TMH}\ residues}\end{equation}</script><p>残基水平召回率$REC_R$，定义如下</p>
<script type="math/tex; mode=display">\begin{equation}
  REC_R = \frac{number\ of \ correctly\ predicted\ \mathbf{TMH}\ residues}{number\ of \ observed\ \mathbf{TMH}\ residues}
\end{equation}</script><p>螺旋水平准确率$PRE_H$反映了准确预测TMH的分数，定义如下：</p>
<script type="math/tex; mode=display">\begin{equation}PRE_H=\frac{number\ of \ correctly\ predicted\ \mathbf{TMH}s}{number\ of \ predicted\ \mathbf{TMH}s}\end{equation}</script><p>一个TMH只有满足以下条件才视为正确预测：</p>
<ol>
<li>预测的TMH的末端位置与真实TMH相差不超过5个残基</li>
<li>预测TMH与真实TMH相覆盖的部分至少是较长那条的一半</li>
</ol>
<p>以上两个标准比过去使用的都要严格，且被应用在最近许多的研究中。</p>
<p>螺旋水平召回率$REC_H$对应$PRE_H$定义如下：</p>
<script type="math/tex; mode=display">\begin{equation}PRE_H=\frac{number\ of \ correctly\ predicted\ \mathbf{TMH}s}{number\ of \ observed\ \mathbf{TMH}s}\end{equation}</script><p>完全正确预测TMH的蛋白质数量$V_p$，定义如下：</p>
<script type="math/tex; mode=display">\begin{equation}
  V_p=\sum_{i=1}^{N}x_i;x_i=
  \begin{cases}
    1,\mathit{if}\ PRE_{Hi} = REC_{Hi}=1 \\
    0, \mathit{else}
  \end{cases}
\end{equation}</script><p>这个方程中一个TMP被正确预测需要满足以下两个条件：</p>
<ol>
<li>预测TMH的数量和真实TMH的数量一致</li>
<li>所有真实TMH都被正确预测出来，即召回率、准确率都为1</li>
</ol>
<p>完全正确预测跨膜拓扑的蛋白质数量$V_{top}$，定义如下：</p>
<script type="math/tex; mode=display">\begin{equation}
  V_{top}=\sum_{i=1}^{N}y_i;y_i=
  \begin{cases}
    1,\mathit{if}\ PRE_{Hi}=REC_{Hi}=TOP_{i}=1 \\
    0, \mathit{else}
  \end{cases}
\end{equation}</script><p>当蛋白质所有非TMH的内外方向都正确预测时，$TOP$取1。<br>Matthews Correlation Coefficient(MCC)，方向预测是一个二值分类问题，因此我们用MCC来评价效果定义如下：</p>
<script type="math/tex; mode=display">\begin{equation}MCC=\frac{TP\times TN - FP \times FN}{\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}\end{equation}</script><p>$TP,TN,FP,FN$分别代表了真正样本、真负样本、假正样本、假负样本的数量。</p>
<p>在这些指标中，$PRE_H$、$REC_H$、$V_P$、$V_{top}$、$MCC$最为重要，因为他们反映了真实的效果。</p>
<h1 id="3-Results-and-Discussions"><a href="#3-Results-and-Discussions" class="headerlink" title="3. Results and Discussions"></a>3. Results and Discussions</h1><h2 id="3-1-Results"><a href="#3-1-Results" class="headerlink" title="3.1 Results"></a>3.1 Results</h2><p>为了做一个全面的对比，我们应用了15个这个领域最新的方法，他们分别为TMSEG、MEMSAT3、MEMSAT-SVM，MemBrain、TOPCONS、CCTOP、OCTOPUS、SPOCTUPUS、PHilius、Phobius、PolyPhobius、TMHMM2、SCAMPI、TMpred、TopGraph</p>
<h3 id="Comparison-to-the-state-of-the-art-methods"><a href="#Comparison-to-the-state-of-the-art-methods" class="headerlink" title="Comparison to the state-of-the-art methods"></a>Comparison to the state-of-the-art methods</h3><p>Table1展示了测试集在不同算法下的效果。这15个算法中，只有TMSEG被安装且运行在本地电脑下，其他算法的结果都通过他们开放的服务器获得。对于MEMSAT3和MemBrain2.0，他们仅用39个测试蛋白进行效果评价，因为2D2CT蛋白太小了(27个残基大小)，并超过了他们的应用范围。MemBrain2.0只能预测TMH；因此，与方向判断预测相关的效果没有被计算。对于TopGraph，他的服务器不能对3RKOK、4B4AA进行预测，所以评价结果只针对余下38个蛋白，表1仅使用了6个指标：$PRE_R,REC_R,PRE_H,REC_H,V_p,V_{top}$</p>
<img src="/2020/02/20/translate-MemBrain/Table1-1.png" title="Table1-1">
<!-- ![](translate-MemBrain/Table1-1.png) -->
<img src="/2020/02/20/translate-MemBrain/Table1-2.png" title="Table1-2">
<!-- ![](translate-MemBrain/Table1-2.png) -->
<p>对于Table1，我们可以看到所有算法都能有很高的$PRE_R$，最大的$PRE_R$是由CCTOP达到的0.931。$PRE_R$的最大值和最小值仅相差5.8%，这意味着所有预测的TMH残基是确信的(<code>confident</code>)。然而相对于$PRE_R$，$REC_R$的差距十分大，MemBrain3.0为0.904，比其他算法高出14.5%至23.6%，这说明我们的模型能找出更多的TMH残基。螺旋水平上的评价中，MemBrain 3.0达到了0.808的$PRE_H$和0.819的$REC_H$，而其他对比算法中最高的只有0.641的$PRE_H$和0.611的$REC_H$。</p>
<p>有两个主要原因导致了以上差距。第一个是因为MemBrain3.0采用了较新的深度学习模型，它优于传统的机器学习算法如SVM，它能通过非线性转换从输入特征集合中生成更具有代表性的特征，且这些特征更加的鲁棒有效。第二个原因是MemBrain采用的TMH定义不同于其他的算法。具体而言，MemBrain3.0把尾端也视为TMH的一部分，其他算则没有。因此他们会把尾端残基视为非TMH。</p>
<p>为了更好的试验MemBrain3.0的能力，我们也计算了在没有尾端定义下的效果。Membrain3.0的$REC_R$是0.959，15个对比算法中最高的$REC_R$是0.874。这也证明了MemBrain3.0对于预测内嵌残基也十分有效。因为MemBrain3。0中尾端残基被视作正样本，预测的TMH会比真实的TMH更长。这意味着即使预测TMH和正确TMH的重叠部分比较长但是因为结束点的位置不同会导致预测不如预想中的正确。为了验证这点，我们重新计算了在如下标准下的测量值：如果真实TMH和预测TMH重叠部分至少有更长的一段的一半长那么TMH视为正确预测。MemBrain3.0在螺旋水平上的F1分数达到了最好的效果，它的定义如下：</p>
<script type="math/tex; mode=display">\begin{equation}
  F1_{Hi}=2\times \frac{PRE_{Hi}\times REC_{Hi}}{PRE_{Hi}+REC_{Hi}}
\end{equation}</script><p>我们也对MemBrian和对比算法螺旋水平的F1值进行了t检验，最大的p值是7.6e-3，低于统计有效性阈值0.05，说明了这个提升是有效的。</p>
<p>对40个测试蛋白，MemBrain3.0能正确预测其中21种蛋白的TMH，即他们视为正确的TMH($PRE_{Hi}=REC_{Hi}=1$)。对于等式(10)所定义的$V_p$标准而言，这不是简单的任务。对于$V_p$，第二优的预测器是TMSEG，它能正确预测40个中的15个蛋白。基于能正确预测出TMH的蛋白，我们评价了方向预测的效果，21个正确预测的蛋白中MemBrain3.0能正确预测出其中20个蛋白的里外侧方向，第二优的算法是TMSEG，它$V_{top}$的值是13。</p>
<h3 id="Dynamic-threshold-strategy-imprives-TMH-prediction"><a href="#Dynamic-threshold-strategy-imprives-TMH-prediction" class="headerlink" title="Dynamic threshold strategy imprives TMH prediction"></a>Dynamic threshold strategy imprives TMH prediction</h3><p>如预测模型章节中所提到的，我们在二值化原生预测分数时应用了动态阈值策略。对比使用固定的阈值，动态阈值策略可以解决欠划分的问题。Figure 4给了我们两个离子，x轴上的线是根据原生预测分数标注的。图的底部有三条柱子，蓝柱黑柱分别代表根据动态阈值和固定阈值所判定的TMH。绿柱是蛋白真实的TMH结构。Figure 4(a)是蛋白质4HYGA的示意图。在第36个和92个残基之间有两个相邻的TMH，由5个的残基组成的loop所连接。在这个例子中，因为TMH残基在输入滑窗中占主要(12个TMH残基对于17个残基长的滑窗)所以对于loop部分的预测分数会偏高。如果使用固定阈值则两段TMH会预测成一段。应用动态阈值时，这个问题能被纠正。Figure 4(b)展示了对于蛋白质4WZ7F的欠划分情况。在第28个和第70个残基之间有两个相邻的TMH由一段4个残基长的loop相连。应用动态阈值后，他们都能被正确预测。</p>
<img src="/2020/02/20/translate-MemBrain/Fig4.png" title="Fig4">
<!-- ![](translate-MemBrain/Fig4.png) -->
<blockquote>
<p>Figure4 欠划分问题的示意图。x轴上的蓝线标出了原生预测分数，蓝柱和黑柱分别代表使用动态阈值和固定阈值所预测的TMH，绿柱是TMH的真实结构，动态阈值能够通过逐步提高阈值来重新检测潜在的欠划分TMH以解决问题。</p>
</blockquote>
<p>Table2展示了测试集在动态阈值策略下的效果优于其他算法。动态阈值略降低了$PRE_R$ 3.3\%，大幅度提高了$REC_R$ 6.1%。分别提高了$PRE_H$和$REC_H$ 4.6%,4.7%。正确预测的TMH从19提高到了21。这些提高都证明了动态阈值的有效性。</p>
<img src="/2020/02/20/translate-MemBrain/Table2.png" title="Table2">
<!-- ![](translate-MemBrain/Table2.png) -->
<p>为了评价在大规模数据集下动态阈值的效果，我们进行了10折内嵌交叉验证如先前的课题所提到的。具体而言，我们的训练集和验证集被分为10份，其中第1部分被作为测试集，第2到第10分被轮流作为验证集，则剩下的8分作为训练集。这共生成了9个预测模型。9个模型对第1部分的预测取平均则视为最终的预测。对其他9个部分也进行了相同的过程处理。</p>
<h3 id="Stepwise-Max-Min-assignment-algorithm-enhances-the-orientation-prediction"><a href="#Stepwise-Max-Min-assignment-algorithm-enhances-the-orientation-prediction" class="headerlink" title="Stepwise Max-Min assignment algorithm enhances the orientation prediction"></a>Stepwise Max-Min assignment algorithm enhances the orientation prediction</h3><p>Table 3展示了测试集上使用固定阈值和使用stepwiseMMA算法的效果。我们用了两类测试指标来评价，第一种包括$MCC^{40}$和$V^{40}_{top}$，他们都是用40个测试蛋白的真实TMH进行计算的。对于固定阈值，两者分别为0.594和23，应用了MMA算法后两者分别提高到0.658，29。第二类指标是$MCC^{21}$和$V^{21}_{top}$，他们仅只算Table2提到的21个正确预测TMH的测试蛋白。对比固定阈值，MMA算法两者分别提高了0.283和8。这些结果说明了我们提出的stepwiseMMA算法在决策水平更为有效。</p>
<p>为了评价MMA算法在大规模数据集下的效果。我们同样对训练集和验证集进行了10折交叉验证。10折的处理如TMH预测试验中一致。</p>
<img src="/2020/02/20/translate-MemBrain/Table3.png" title="Table3">
<!-- ![](translate-MemBrain/Table3.png) -->
<h3 id="Performance-of-ensemble-learing-models"><a href="#Performance-of-ensemble-learing-models" class="headerlink" title="Performance of ensemble learing models"></a>Performance of ensemble learing models</h3><p>集成是一种在机器学习中广泛应用的算法。他利用几个有区别的模型来提高效果，Table4和Table5分别展示了在TMH预测和方向判别上集成的有效性。TMH预测中2个不同尺度输入的残差网络取平均作为集成。从Table 4，我们可以看到达到$PRE_H$和$REC_H$的是集成模型，前者为0.808，后者为0.819，对比2个残差网络最好的效果，两者提高了3.8%和4.7%。此外，使用集成模型后正确预测TMH的蛋白质增加了两个。</p>
<img src="/2020/02/20/translate-MemBrain/Table4.png" title="Table4">
<!-- ![](translate-MemBrain/Table4.png) -->
<p>如上文所述，方向预测中，5个候选结点被提取分别带有2，4，6，8，10个残基在TMH中11，9，7，5，3分残基在非TMH中。5个候选结点的预测被平均作为集成的结果，Table5对比了单个候选结点和集成模型。集成模型正确预测21个测试蛋白中的20个(Table 2中提到的21个)，而单独的结点最好只有18个，$MCC^21$对比最好的单个结点预测，提高了9.4%。</p>
<img src="/2020/02/20/translate-MemBrain/Table5.png" title="Table5">
<!-- ![](translate-MemBrain/Table5.png) -->
<h3 id="Performance-on-difficult-TMHs"><a href="#Performance-on-difficult-TMHs" class="headerlink" title="Performance on difficult TMHs"></a>Performance on difficult TMHs</h3><p>TMP结构十分复杂并有许多特殊情况。我们主要聚集3类困难的TMH:长TMH、半TMH、连续TMH。长TMH指TMH长度超过30个残基的，半TMH只横跨半个膜，氮端碳端都在同一侧。连续TMH指一对TMH通过一个短于3个残基的loop连接的。一个连续TMH只有两个TMH都正确预测才视为正确预测。40个测试蛋白中有28个长TMH，11个连续TMH，3个半TMH。</p>
<p>Table 6展示了不同算法对于测试集中难TMH的预测效果。MemBrain3.0把11个连续TMH中的8个正确预测。而其他15个算法中最好的也只是预测出6对。对于半TMH，MemBrain3.0正确预测出全部，其他对比模型最好预测出2个。对于长TMH，Membrain3.0成功预测出其中的23个，是所有算法中最好的。</p>
<p>我们同样通过10这内嵌交叉验证对训练集和验证集中的难TMH进行了评价。共有150个长TMH，13个半TMH，81对连续TMH在两个集合中。MemBrain3.0正确预测除了85个长TMH，9个半TMH，50个连续TMH。高于其他所有对比对算法。</p>
<img src="/2020/02/20/translate-MemBrain/Table6.png" title="Table6">
<!-- ![](translate-MemBrain/Table6.png) -->
<h2 id="3-2-Discussion"><a href="#3-2-Discussion" class="headerlink" title="3.2 Discussion"></a>3.2 Discussion</h2><h3 id="Amio-acid-distribution-of-the-buried-and-tail-parts"><a href="#Amio-acid-distribution-of-the-buried-and-tail-parts" class="headerlink" title="Amio acid distribution of the buried and tail parts"></a>Amio acid distribution of the buried and tail parts</h3><p>如Figure5所示，尽管所有的TMH的内嵌部分和尾端部分都是主要有疏水的残差组成，但是他们的氨基酸分布是非常不同的。具体而言内嵌部分的疏水残基比例是远高于尾端部分的。这是因为内嵌部分暴露在磷脂(<code>phospholipid</code>)中，尾端在暴露在溶剂之中。如果有很多疏水残基在内嵌部分的话，分子构象的自由能量会降低。我们对尾部区域(TMH末端)的残基进行了统计，同时对尾端残基也做了同样的统计，分布可见<em>Figure S4</em>。因为内嵌部分和尾端部分的残基疏水性不同，TMH的边界会很难被准确预测出来。</p>
<img src="/2020/02/20/translate-MemBrain/Fig5.png" title="Fig5">
<!-- ![](translate-MemBrain/Fig5.png) -->
<blockquote>
<p>Figure 5内嵌部分和尾端部分的氨基酸分布图。统计是基于训练集和验证集共318个蛋白质，氨基酸在x轴上按照Kyte-Doolittle 疏水性规模进行排列。y轴代表了出现频率。内嵌部分的疏水性残基比例远大于尾端部分的残基。</p>
</blockquote>
<h3 id="Length-distributions-of-observed-TMHs"><a href="#Length-distributions-of-observed-TMHs" class="headerlink" title="Length distributions of observed TMHs"></a>Length distributions of observed TMHs</h3><p>考虑到MemBrain3.0建模的范围包括了尾端，所以TMH会更长。如Figure6中我们基于测试集和验证集的蛋白质分别画了带有尾端和不带有尾端的TMH长度分布。带有尾端的TMH对应拟合高斯分布的平均值是23.1，大雨没有带尾端的TMH(20.4)，我们也对两种TMH长度分布进行了威尔科克森秩和检验(<code>Wilcoxon rank-sum test</code>)。p值是3.72e-37。证明了这个差距是有效的，同时考虑尾端的长度分布范围更加宽。</p>
<img src="/2020/02/20/translate-MemBrain/Fig6.png" title="Fig6">
<!-- ![](translate-MemBrain/Fig6.png) -->
<blockquote>
<p>Figure 6 TMH有尾端和没有尾端的长度分布。统计基于训练集和验证集共318个蛋白，他们的长度分布拟合出的高斯分布，两个均值分别为23.1，20.4。</p>
</blockquote>
<h3 id="Length-distributions-of-predicted-TMHs"><a href="#Length-distributions-of-predicted-TMHs" class="headerlink" title="Length distributions of predicted TMHs"></a>Length distributions of predicted TMHs</h3><p>对于所有算法，我们计算了测试集中预测TMH的长度分布，他们的拟合分布在Figure7画出。注意SPOCTUPUS,OCTUPUS,SCAMPI,TMHMM2,TopGraph和TOPCONS没有被包括，因为他们预测出得TMH都是固定长度，例如SCAMPI和TOPCONS都是主要输出21残基长的TMH。</p>
<p>这个结构说明了MemBrain3.0预测出的TMH长度分布个放假接近真实TMH长度分布。他们的均值分别问23.5、24.4。剩下9个算法中次之接近的均值为22.7，由MEMSAT3所实现。导致长度分布差别的一个原因是MemBrain3.0结合了尾端进行建模，而其他们没有。</p>
<img src="/2020/02/20/translate-MemBrain/Fig7.png" title="Fig7">
<!-- ![](translate-MemBrain/Fig7.png) -->
<blockquote>
<p>Figure7 真实TMH和预测TMH的长度分布，MemBrain3.0拟合高斯分布的均值最为接近带有尾端的TMH的分布，均值分别为23.5和24.4。<br>The mean of the fitted Gaussian distribution of TMHs predicted by MemBrain 3.0 is the closest to that of the observed TMHs including tails.</p>
</blockquote>
<h3 id="Incorporating-tail-parts-poses-difficulties-for-TMH-predicition"><a href="#Incorporating-tail-parts-poses-difficulties-for-TMH-predicition" class="headerlink" title="Incorporating tail parts poses difficulties for TMH predicition"></a>Incorporating tail parts poses difficulties for TMH predicition</h3><p>为了验证这一点，我们用两种不同的TMH定义(是否带有尾端)训练集寻两个SVM。他们超参数都取决于验证集的效果。并最终在测试集进行对比，结果见<em>Table S15</em>，尽管在残基水平没有太大的差距，$PRE_H$和$REC_H$在带有尾端的定义下下降了17%和14.1%。正确预测TMH的蛋白质数量也下降了10个，这些结果说明了考虑尾端后预测TMH会更加苦难。</p>
<h3 id="Deep-learning-is-an-effective-model-for-TMH-prediction"><a href="#Deep-learning-is-an-effective-model-for-TMH-prediction" class="headerlink" title="Deep learning is an effective model for TMH prediction"></a>Deep learning is an effective model for TMH prediction</h3><p>我们在MemBrain3.0中提出了使用深度学习模型来预测TMH，为了验证有效性，在相同的训练集下，我们训练了一个SVM分类器进行对比，基于深度学习的MemBrain3.0比SVM分类器分别提高了$PRE_H$和$REC_H$ 7.70%和10.8%。证明了这个任务中深度学习的有效性。</p>
<h3 id="performance-on-complete-protein-sequences"><a href="#performance-on-complete-protein-sequences" class="headerlink" title="performance on complete protein sequences"></a>performance on complete protein sequences</h3><p>先前的测试中MemBrain3.0通过从OPM数据库提取蛋白质序列进行构建，这些序列是蛋白质作用域的序列(<code>domain sequences</code>)并且对于完整氨基酸序列。然而评估MemBrain3.0在实际应用中对于完整序列是否仍旧有效是十分重要的。我们首先将OPM的作用域序列用SIFTS映射到UniProtKB数据库中的完整蛋白质序列中。训练集和验证集中318个序列内，257个序列能在UniProtKB中够找到他们对应的完整序列。对于40个测试序列，能找到30个。然后我们对于这些导出的完整序列根据OPM数据库作用域序列的标签进行标注。最后对于这30个测试序列和257个训练/验证序列分别用Membrain3.0模型和用内嵌10折交叉验证得到的模型预测TMH。效果对比见Table7，对于完整序列中的残基，只有那些在作用域内的部分被标注，所以有很多残基没有标签，因此我们只计算$REC_H$和$REC_R$进行评估。</p>
<p>如Table7所示，对于测试集和训练/验证集，$REC_R$在完整序列和作用域序列的差值都很小。而$REC_H$，它的表现分别下降了3%和2%，这是很小的数字。这说明了MemBrain3.0在完整蛋白质序列下的预测依然有效。这细小的差值可能是由作用域序列和完整序列生成的特征不同导致的，如不同的MSA值会导致PSSM特征的变化。</p>
<img src="/2020/02/20/translate-MemBrain/Table7.png" title="Table7">
<!-- ![](translate-MemBrain/Table7.png) -->
<h3 id="On-signal-peptides-recognition"><a href="#On-signal-peptides-recognition" class="headerlink" title="On signal peptides recognition"></a>On signal peptides recognition</h3><p>信号肽会经常误判为TMH，因为他们都含有很多疏水性的氨基酸。已经有很多预测器被发明来区分信号肽和TMH，并用来识别切割位点。Singal-3L 2.0是我们最近发明的，它被集成到MemBrain3.0中来预测信号肽。在MemBrain3.0的网页服务器中，signal-3L 2.0被首先应用来检测信号肽，如果检测到，切割位点前的残基会被移除，然后剩下的序列会输入到MemBrain3.0的模型汇总，最后Singal—3L 2.0和MemBrain3.0的预测结果会被合并。通过这种方法，MemBrain3.0可以避免对信号肽作出假正样本的预测。</p>
<h3 id="Sequence-encoding-features-play-an-important-role"><a href="#Sequence-encoding-features-play-an-important-role" class="headerlink" title="Sequence encoding features play an important role"></a>Sequence encoding features play an important role</h3><p>正如上面介绍，我们用了3类蛋白质特征来做TMH预测：PSSM、HMMprofile、结构特征，将这三类特征有7种排列组合，我们用这7种组合训练了7个残基水平上的残差网络，如Figure8(a)展示了$PRE_H$和$REC_H$的效果。不同的特征做出的贡献是不同的，同时使用了3类特征的组合是效果最好的。对比其他六种组合，$PRE_H$、$REC_H$分别提高了5.1%和6.1%。<br>我们也用了所有特征的排列组合取训练多个方向预测模型做对比(Figure8(b))。这个结果说明了进化信息如PSSM和HMMprofile比起结构特征和疏水性规模有更大的作用。HMMprofile看似比PSSM更重要。单独用HMMprofile训练的模型的$MCC^{40}$是0.634，对单独用PSSM训练的仅有0.447。此外，所有特征的组合的$MCC^{40}$高于0.6，它也包含了HMMprofile，说明了它的有效性。我们也尝试使用不同的疏水性规模，例如Engelman规模，Kessel和Ben-tal规模和Steve White规模。这些结果显示他们之间没有很大的区别。综上，拥有最好效果的模型是由HMMprofile和疏水性规模组合的特征训练。他们$MCC^{40}$、$V_{top}^{40}$、$MCC^{21}$、$V^{21}_{top}$的值分别为0.658，29，0.969，20。</p>
<img src="/2020/02/20/translate-MemBrain/Fig8-1.png" title="Fig8-1">
<!-- ![](translate-MemBrain/Fig8-1.png) -->
<img src="/2020/02/20/translate-MemBrain/Fig8-2.png" title="Fig8-2">
<!-- ![](translate-MemBrain/Fig8-2.png) -->
<blockquote>
<p>Figure 8 对于TMH和方向预测，不同特征有不同的重要性，TMH预测最好效果的模型由使用PSSM、HMMprofile、结构特征训练的模型。对于方向预测，最好效果的模型由使用HMMprofile和疏水性规模特征训练的模型。</p>
</blockquote>
<h3 id="Searching-larger-databases-leads-to-better-performance"><a href="#Searching-larger-databases-leads-to-better-performance" class="headerlink" title="Searching larger databases leads to better performance"></a>Searching larger databases leads to better performance</h3><p>进化信息特征如PSSM和HMMprofile通常通过在巨大的数据库中搜索同源的序列。数据库的大小一定程度上决定了搜索同源蛋白质的多少，它会影响特征的质量。而特征质量最终会影响算法的效果。</p>
<p>Uniprot20和Uniclust30是两个常用的HHsuite-format 数据库。前者包含了从Uniprot数据库中收集的高质量的蛋白质序列。后者则通过在UniprotKB中以成对30%相似度的序列进行聚类。Uniclust30 有Uniprot20的两倍大，这意味着用Uniclust30生成的HMMprofile更准确。Uniref50用BLAST工具包中的一个程序生成。它由UniProtKB中聚类过的序列组成。NR是一个BLAST网站分布的一个非冗余(无重复序列)的数据库。它拥有从多个数据库收集来的序列，如Refseq,PDB,SwissProt，它比Uniref大得多。</p>
<p>Table 8和Table 9分别显示了序列数据库对TMH预测和方向预测的影响。从那我们可以看到数据库越大，算法预测的越准确，例如使用Uniprot20和Uniref50作为数据库，他们的$PRE_H$和$REC_H$分别为0.743和0.758。通过替换成Uniref50和NR，这两个测量值分别提高2.9%和1.4%。使用Uniclust30和NR时能达到最好的效果，$PRE_H$为0.808和$REC_H$为0.819。在做方向预测时也发现了相同的状况。当使用Uniclust30数据库查找时$MCC^{40}$提高了7.2%，并有4个蛋白质被分为正确预测拓扑的蛋白质。</p>
<img src="/2020/02/20/translate-MemBrain/Table8.png" title="Table8">
<!-- ![](translate-MemBrain/Table8.png) -->

<!-- ![](translate-MemBrain/Table9.png) -->
<h1 id="4-Conclusions"><a href="#4-Conclusions" class="headerlink" title="4. Conclusions"></a>4. Conclusions</h1><p>尽管TMP拓扑预测已经作为一个有趣的主题有很长一段时间了，也有很多模型被发明，但是精确预测TMH和判断方向依然是一个挑战，尤其当我们使用了更严格评判标准。一个主要原因时TMP结构十分复杂有很多特殊情况如半TMH，长TMH和连续TMH。这些都导致了预测中很大的困难。甚者，TMH的尾端在相关工作中通常会排除在外，但实际上尾端在生理过程中起着很重要的作用。在这篇论文中，我们拓宽了建模的范围以覆盖尾端并退出了一个新的数据驱动的基于深度学习的模型MemBrain3.0来提高拓扑结构的预测效果。在我们认知中，这是深度学习算法第一次应用在这个领域。在决策上，MemBrain3.0结合了动态阈值策略和stepwise极大极小分配算法，他们都提供了更好的效果。我们的试验说明了设计模式对于精准预测TMH和判断方向时什么重要的。未来的工作包括了精准预测TMP连接点(<code>contact</code>)和对预测的连接点和MTH重构3D结构。并提高对TMH和信号肽的区分效果。</p>
<h1 id="5-说明"><a href="#5-说明" class="headerlink" title="5. 说明"></a>5. 说明</h1><p>原文中所有support informations(i.e. Table S,Figure S)均在pdf中找不到，条件受限没有办法购买原文以下载，已向原作者发送邮件进行索取。</p>

    </div>

    
    
    
        
      

      <footer class="post-footer">
          
            
          
          <div class="post-tags">
            
              <a href="/tags/deep-learning/" rel="tag"># deep_learning</a>
            
              <a href="/tags/bioinformation/" rel="tag"># bioinformation</a>
            
              <a href="/tags/ResNet/" rel="tag"># ResNet</a>
            
          </div>
        

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2019/09/29/read-DEMO-net/" rel="next" title="DEMO-net 阅读">
                  <i class="fa fa-chevron-left"></i> DEMO-net 阅读
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
            </div>
          </div>
        
      </footer>
    
  </div>
  
  
  
  </article>

  </div>


          </div>
          

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Abstract"><span class="nav-number">1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Keywords"><span class="nav-number">2.</span> <span class="nav-text">Keywords</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-Introduction"><span class="nav-number">3.</span> <span class="nav-text">1. Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-Material-and-Methods"><span class="nav-number">4.</span> <span class="nav-text">2. Material and Methods</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-Dataset"><span class="nav-number">4.1.</span> <span class="nav-text">2.1 Dataset</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-protein-sequence-features"><span class="nav-number">4.2.</span> <span class="nav-text">2.2 protein sequence features</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Position-specific-scoring-matrix-PSSM"><span class="nav-number">4.2.1.</span> <span class="nav-text">Position-specific scoring matrix PSSM</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hidden-Markov-Model-profile"><span class="nav-number">4.2.2.</span> <span class="nav-text">Hidden Markov Model profile</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Predicted-structural-features"><span class="nav-number">4.2.3.</span> <span class="nav-text">Predicted structural features</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hydrophobicity-scales"><span class="nav-number">4.2.4.</span> <span class="nav-text">Hydrophobicity scales</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-Prediction-model"><span class="nav-number">4.3.</span> <span class="nav-text">2.3 Prediction model</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Multiscale-deep-learning-based-TMH-prediction-model"><span class="nav-number">4.3.1.</span> <span class="nav-text">Multiscale deep learning-based TMH prediction model</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-The-small-scale-residue-based-Resnet"><span class="nav-number">4.3.1.1.</span> <span class="nav-text">(1) The small-scale residue-based Resnet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-The-large-scale-entire-sequence-based-Resnet"><span class="nav-number">4.3.1.2.</span> <span class="nav-text">(2) The large-scale entire-sequence-based Resnet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-Dynamic-threshold-strategy"><span class="nav-number">4.3.1.3.</span> <span class="nav-text">(3) Dynamic threshold strategy</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Inside-outside-orientation-prediction"><span class="nav-number">4.3.2.</span> <span class="nav-text">Inside/outside orientation prediction</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-SVM-based-orientation-prediction-model"><span class="nav-number">4.3.2.1.</span> <span class="nav-text">(1) SVM-based orientation prediction model</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-Stepwise-Max-Min-assignment-MMA-algorithm"><span class="nav-number">4.3.2.2.</span> <span class="nav-text">(2) Stepwise Max-Min assignment(MMA) algorithm</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-4-Evaluation-measures"><span class="nav-number">4.4.</span> <span class="nav-text">2.4 Evaluation measures</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-Results-and-Discussions"><span class="nav-number">5.</span> <span class="nav-text">3. Results and Discussions</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-Results"><span class="nav-number">5.1.</span> <span class="nav-text">3.1 Results</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Comparison-to-the-state-of-the-art-methods"><span class="nav-number">5.1.1.</span> <span class="nav-text">Comparison to the state-of-the-art methods</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Dynamic-threshold-strategy-imprives-TMH-prediction"><span class="nav-number">5.1.2.</span> <span class="nav-text">Dynamic threshold strategy imprives TMH prediction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Stepwise-Max-Min-assignment-algorithm-enhances-the-orientation-prediction"><span class="nav-number">5.1.3.</span> <span class="nav-text">Stepwise Max-Min assignment algorithm enhances the orientation prediction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Performance-of-ensemble-learing-models"><span class="nav-number">5.1.4.</span> <span class="nav-text">Performance of ensemble learing models</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Performance-on-difficult-TMHs"><span class="nav-number">5.1.5.</span> <span class="nav-text">Performance on difficult TMHs</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-Discussion"><span class="nav-number">5.2.</span> <span class="nav-text">3.2 Discussion</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Amio-acid-distribution-of-the-buried-and-tail-parts"><span class="nav-number">5.2.1.</span> <span class="nav-text">Amio acid distribution of the buried and tail parts</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Length-distributions-of-observed-TMHs"><span class="nav-number">5.2.2.</span> <span class="nav-text">Length distributions of observed TMHs</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Length-distributions-of-predicted-TMHs"><span class="nav-number">5.2.3.</span> <span class="nav-text">Length distributions of predicted TMHs</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Incorporating-tail-parts-poses-difficulties-for-TMH-predicition"><span class="nav-number">5.2.4.</span> <span class="nav-text">Incorporating tail parts poses difficulties for TMH predicition</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Deep-learning-is-an-effective-model-for-TMH-prediction"><span class="nav-number">5.2.5.</span> <span class="nav-text">Deep learning is an effective model for TMH prediction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#performance-on-complete-protein-sequences"><span class="nav-number">5.2.6.</span> <span class="nav-text">performance on complete protein sequences</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#On-signal-peptides-recognition"><span class="nav-number">5.2.7.</span> <span class="nav-text">On signal peptides recognition</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Sequence-encoding-features-play-an-important-role"><span class="nav-number">5.2.8.</span> <span class="nav-text">Sequence encoding features play an important role</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Searching-larger-databases-leads-to-better-performance"><span class="nav-number">5.2.9.</span> <span class="nav-text">Searching larger databases leads to better performance</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-Conclusions"><span class="nav-number">6.</span> <span class="nav-text">4. Conclusions</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-说明"><span class="nav-number">7.</span> <span class="nav-text">5. 说明</span></a></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">GimCung Ho</p>
  <div class="site-description" itemprop="description">stay hungry stay foolish</div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">5</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">标签</span>
        </a>
      </div>
    
  </nav>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">GimCung Ho</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.4.0</div>


    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_pv">总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">总访客<span id="busuanzi_value_site_uv"></span>人</span>
    <span class="post-meta-divider">|</span>



        












        
      </div>
    </footer>
  </div>

  


  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.4.0"></script><script src="/js/motion.js?v=7.4.0"></script>
<script src="/js/schemes/pisces.js?v=7.4.0"></script>
<script src="/js/next-boot.js?v=7.4.0"></script>



  





















  

  
    
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

    
  

  

  

</body>
</html>
